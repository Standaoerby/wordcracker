# scripts/make_corpus.py
# üì¶ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫–∞ + –æ—á–∏—Å—Ç–∫–∞ + —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

import subprocess
import argparse
from pathlib import Path
import shutil
from collections import Counter


def run_script(script, *args):
    cmd = ["python", script] + list(args)
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫: {' '.join(cmd)}")
    subprocess.run(cmd, check=True)


def count_tokens(text_path: Path):
    with open(text_path, encoding='utf-8') as f:
        text = f.read()
    words = text.lower().split()
    total = len(words)
    freqs = Counter(words)
    rare = [w for w, c in freqs.items() if c == 1]
    midfreq = [w for w, c in freqs.items() if 3 <= c <= 10]
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {text_path.relative_to(Path.cwd())}")
    print(f"  üëâ –í—Å–µ–≥–æ —Å–ª–æ–≤: {total:,}")
    print(f"  üîπ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freqs):,}")
    print(f"  üß© –†–µ–¥–∫–∏—Ö (1 —Ä–∞–∑): {len(rare):,}")
    print(f"  ‚öñÔ∏è  –ß–∞—Å—Ç–æ—Ç–∞ 3-10: {len(midfreq):,}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--author", type=str, required=True, help="–ò–º—è –∞–≤—Ç–æ—Ä–∞ (–ø—Ä–∏–º–µ—Ä: wodehouse)")
    args = parser.parse_args()

    author = args.author.lower().replace(" ", "_")
    raw_path = Path("raw_books") / author
    data_path = Path("data") / author

    # 1. –°–∫–∞—á–∏–≤–∞–µ–º –∫–Ω–∏–≥–∏
    run_script("scripts/gutenberg_import.py")

    # 2. –ß–∏—Å—Ç–∏–º –∏—Ö
    run_script("scripts/text_cleaner.py", "--input", "raw_books", "--output", "data")

    # 3. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ –∫–∞–∂–¥–æ–π –∫–Ω–∏–≥–µ
    for book in data_path.glob("*.txt"):
        count_tokens(book)


if __name__ == "__main__":
    main()
